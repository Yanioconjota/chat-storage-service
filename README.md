# ğŸ“¦ Ollama Storage Service

A microservice built with FastAPI that receives prompts and responses from another API and stores them in MongoDB (hosted on Railway).

---

## ğŸš€ Features
- FastAPI-based microservice
- MongoDB integration using PyMongo
- Clean structure ready for Docker & scaling
- `.env` support for easy configuration

---

## ğŸ“ Structure
```
ollama-storage-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ models.py            # Pydantic models
â”‚   â”œâ”€â”€ database.py          # MongoDB connection
â”‚   â””â”€â”€ routes/
â”‚       â””â”€â”€ save.py          # /save endpoint
â”œâ”€â”€ .env                     # Env variables
â”œâ”€â”€ .env.template            # Sample config
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ Dockerfile               # Docker image config
â”œâ”€â”€ docker-compose.yml       # Run locally
â””â”€â”€ README.md                # Documentation
```

---

## âš™ï¸ Environment Variables
Create a `.env` file using `.env.template`:

```env
MONGO_URI=your_mongo_connection_string
DB_NAME=ollama
COLLECTION_NAME=responses
```

---

## â–¶ï¸ Run Locally
```bash
# Build and start
docker-compose up --build
```

Service will be available at: [http://localhost:8001/save](http://localhost:8001/save)

---

## ğŸ“¬ POST /save
**Body:**
```json
{
  "prompt": "Why is the sky blue?",
  "response": "Because of Rayleigh scattering..."
}
```

**Response:**
```json
{
  "status": "success",
  "inserted_id": "<mongo_id>"
}
```

---

## ğŸ§  Author
Built with â¤ï¸ by Yanioconjota